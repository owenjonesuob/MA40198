---
title: 'MA40198: Applied Statistical Inference'
author: "20965, 20949 and 20969"
date: "23/11/2018"
output: pdf_document
---


```{r setup, include=FALSE}
# If this document is merged with part 1, we can remove this chunk




knitr::opts_chunk$set(cache = TRUE)


#install.packages("purrr")


# We brought this in in part 1
library(ggplot2)


# These were also in part 1
mcmc_mh <- function(iters, burnin, init_params, init_bs, tuners, b_tuner, y, X, Z, show_plot = TRUE) {
  
  theta_vals <- matrix(NA, nrow = iters+1, ncol = length(init_params))
  colnames(theta_vals) <- names(init_params)
  theta_vals[1, ] <- init_params
  
  b_vals <- matrix(NA, nrow = iters+1, ncol = length(init_bs))
  b_vals[1, ] <- init_bs
  
  acceptance <- rep(NA, iters)
  acceptance_b <- rep(NA, iters)
  
  log_post <- log_posterior(init_params, y, init_bs, X, Z)
  
# Progress bar in console
  pb <- txtProgressBar(min = 0, max = iters, style = 3)
  
  
  # MCMC loop
  for (k in seq_len(iters)) {
    
    
    # "Non-random" parameters
    theta_prop <- rnorm(length(init_params), mean = theta_vals[k, ], sd = tuners)
    
    
    log_post_prop <- log_posterior(theta_prop, y, b_vals[k, ], X, Z)
    
    accept_prob <- exp(log_post_prop - log_post)
    
    if (accept_prob > runif(1)) {
      
      theta_vals[k+1, ] <- theta_prop
      log_post <- log_post_prop
      acceptance[k] <- TRUE
      
    } else {
      
      theta_vals[k+1, ] <- theta_vals[k, ]
      acceptance[k] <- FALSE
    }
    
    
    # "Random" parameters (proposed/accepted separately)
    
    # Now hold other parameters steady
    # Random effects have standard deviation exp(log_sigma_b)
    b_prop <- rnorm(length(init_bs), mean = b_vals[k, ], sd = b_tuner)
    
    # Use (possibly newly accepted) values of theta
    log_post_prop_b <- log_posterior(theta_vals[k+1, ], y, b_prop, X, Z)
    
    accept_prob_b <- exp(log_post_prop_b - log_post)
    
    if (accept_prob_b > runif(1)) {
      
      b_vals[k+1, ] <- b_prop
      log_post <- log_post_prop_b
      acceptance_b[k] <- TRUE
      
    } else {
      
      b_vals[k+1, ] <- b_vals[k, ]
      acceptance_b[k] <- FALSE
    }
    
    setTxtProgressBar(pb, value = k)
  }
  
  
  if (show_plot) {
    
    rows <- floor(sqrt(ncol(theta_vals)))
    par(mfrow = c(rows, rows+(ncol(theta_vals)%%2)))
    
    lapply(names(init_params), function(nm) {
      y <- theta_vals[, nm]
      plot(y, type = "l", main = nm, xlab = "Iteration", ylab = nm)
      rect(0, min(y), burnin, max(y), density = 10, col = "red")
    })
    
    par(mfrow = c(1, 1))
  }
  
  close(pb)
  cat(sprintf("Total acceptance:       %2.3f%%\n", mean(acceptance)*100))
  cat(sprintf("Burned-in acceptance:   %2.3f%%\n", mean(acceptance[-(1:burnin)])*100))
  cat(sprintf("Burned-in b acceptance: %2.3f%%\n", mean(acceptance_b[-(1:burnin)])*100))
  
  list(theta = theta_vals, b = b_vals)
}



mcmc_mh_cov <- function(iters, burnin, init_params, init_bs, cov_matrix, tuner, y, X, Z, show_plot = TRUE) {
  
  theta_vals <- matrix(NA, nrow = iters+1, ncol = length(init_params))
  colnames(theta_vals) <- names(init_params)
  theta_vals[1, ] <- init_params
  
  b_vals <- matrix(NA, nrow = iters+1, ncol = length(init_bs))
  b_vals[1, ] <- init_bs
  
  acceptance <- rep(NA, iters)
  
  log_post <- log_posterior(init_params, y, b_vals[1, ], X, Z)
  
  # Propositions for all iterations
  props <- MASS::mvrnorm(iters, mu = c(init_params, init_bs), Sigma = tuner^2 * cov_matrix)
  
  
  # Progress bar in console
  pb <- txtProgressBar(min = 0, max = iters, style = 3)
  
  
  # MCMC loop
  for (k in seq_len(iters)) {
    
    # Use proposed values for theta and b
    theta_prop <- props[k, 1:length(init_params)]
    b_prop <- props[k, (length(init_params)+1):ncol(props)]
    
    log_post_prop <- log_posterior(theta_prop, y, b_prop, X, Z)
    
    accept_prob <- exp(log_post_prop - log_post)
    
    if (accept_prob > runif(1)) {
      
      theta_vals[k+1, ] <- theta_prop
      b_vals[k+1, ] <- b_prop
      log_post <- log_post_prop
      acceptance[k] <- TRUE
      
    } else {
      
      theta_vals[k+1, ] <- theta_vals[k, ]
      b_vals[k+1, ] <- b_vals[k, ]
      acceptance[k] <- FALSE
    }
    
    
    setTxtProgressBar(pb, value = k)
  }
  
  
  if (show_plot) {
    
    rows <- floor(sqrt(ncol(theta_vals)))
    par(mfrow = c(rows, rows+(ncol(theta_vals)%%2)))
    
    lapply(names(init_params), function(nm) {
      y <- theta_vals[, nm]
      plot(y, type = "l", main = nm, xlab = "Iteration", ylab = nm)
      rect(0, min(y), burnin, max(y), density = 10, col = "red")
    })
    
    par(mfrow = c(1, 1))
  }
  
  close(pb)
  cat(sprintf("Total acceptance:       %2.3f%%\n", mean(acceptance)*100))
  cat(sprintf("Burned-in acceptance:   %2.3f%%\n", mean(acceptance[-(1:burnin)])*100))
  
  list(theta = theta_vals, b = b_vals)
}
```





# Part 2: Fatigue of Materials

The data used in this section can be downloaded from the following location:

```{r load_data}
fatigue <- read.table("http://people.bath.ac.uk/kai21/ASI/fatigue.txt")
set.seed(356476786) # Set a random seed for reproducibility
```


### Section 2.1: Maximum likelihood estimation of distribution parameters

In this section we investigate fatigue in material samples subjected to cyclic loading. Conceptually, this problem is very similar to the problem investigated in Part 1: that is, the Weibull distribution is at the heart of much of the following analysis, and observations are treated as censored or uncensored based on whether or not the fatigue-testing run was completed.

We have assumed that $N_i$, the number of test cycles completed at stress level $s_i$ and with fatigue constant $\gamma$ for the $i$th observation, is given by
$$N_i = \alpha (s_i - \gamma)^\delta \epsilon_i$$
where
$$\epsilon_i \sim \text{Weibull} \left( \text{shape} = 1/\sigma, \; \text{scale} = 1 \right)$$

Immediately we can incorporate the rest of the formula for $N_i$ into the scale parameter of this distribution, obtaining that
$$N_i \sim \text{Weibull} \left( \text{shape} = 1/\sigma, \; \text{scale} = \alpha (s_i - \gamma)^\delta \right)$$

As in Part 1, we can now derive expressions for the negative log-likelihood and its gradient. Note that we reparameterise $\alpha$ and $\sigma$ using a log transform, since both of these parameters must always be greater than 0.

```{r p2q1}
# Expressions for Weibull distribution and survival function
N_prob_const_gamma <- deriv(
  expression(
    -log_sigma - log_alpha - delta*log(s - gamma) +
      ((1/exp(log_sigma)) - 1) * (log(y) - log_alpha - delta*log(s - gamma)) -
      (y / (exp(log_alpha) * (s - gamma)^delta))^(1/exp(log_sigma))
  ),
  namevec = c("log_alpha", "delta", "log_sigma"),
  function.arg = c("y", "s", "min_s", "gamma", "log_alpha", "delta", "log_sigma"),
  hessian = TRUE
)

N_surv_const_gamma <- deriv(
  expression(
    -(y / (exp(log_alpha) * (s - gamma)^delta))^(1/exp(log_sigma))
  ),
  namevec = c("log_alpha", "delta", "log_sigma"),
  function.arg = c("y", "s", "min_s", "gamma", "log_alpha", "delta", "log_sigma"),
  hessian = TRUE
)


# Negative log-likelihood
N_nll_const_gamma <- function(theta, y, gamma, stress, runout) {

  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]

  -sum(
    (1-runout) * N_prob_const_gamma(y, stress, min(stress), gamma, log_alpha, delta, log_sigma),
    runout * N_surv_const_gamma(y, stress, min(stress), gamma, log_alpha, delta, log_sigma)
  )
}


# Gradient of negative log-likelihood
N_nll_gr_const_gamma <- function(theta, y, gamma, stress, runout) {

  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]

  -colSums(rbind(
    (1-runout) * attr(N_prob_const_gamma(y, stress, min(stress), gamma, log_alpha, delta, log_sigma), "gradient"),
    runout * attr(N_surv_const_gamma(y, stress, min(stress), gamma, log_alpha, delta, log_sigma), "gradient")
  ))
}
```

Having defined these functions, we can select a value for $\gamma$ and then optimise over $\mathbf{\theta}$.

```{r p2q1_opt}
# Initial params
theta0 <- c("log_alpha" = 2, "delta" = 1, "log_sigma" = 2)
gamma <- 70

# Minimise negative log-likelihood
N_opt_const_gamma <- optim(
  par = theta0,
  fn = N_nll_const_gamma,
  gr = N_nll_gr_const_gamma,
  y = fatigue$N,
  gamma = gamma,
  stress = fatigue$s,
  runout = fatigue$ro,
  method = "BFGS",
  hessian = TRUE
)
```

Again, just as in Part 1, we can use the negative Hessian returned by `optim()` to calculate standard errors and hence 95% asymptotic confidence intervals for each parameter.

```{r p2q1_std_err}
# Calculate standard errors from inverse Hessian
N_std_err_const_gamma <- sqrt(diag(solve(N_opt_const_gamma$hessian)))

# 95% confidence interval for each parameter
# Note asymptotic distribution of each is normal
round(data.frame(
  val = N_opt_const_gamma$par,
  se = N_std_err_const_gamma,
  lower = N_opt_const_gamma$par - qnorm(0.975)*N_std_err_const_gamma,
  upper = N_opt_const_gamma$par + qnorm(0.975)*N_std_err_const_gamma
), 3)
```

The optimisation is of course dependent on our chosen value of the fatigue limit $\gamma$. By carrying out similar optimisations for different values of $\gamma$ across its potential range, we can see in Figure \ref{fig:p2q1_param_plots} that the parameter values change considerably. In particular, note the apparent negative correlation between `log_alpha` and `delta` (and the steadily tightening 95% confidence intervals for these paramaters); and the rather more dramatic curve that `log_sigma` takes towards the upper end of the range of $\gamma$ (although the confidence interval seems to be of more or less constant width across the whole range).


```{r p2q1_param_plots, echo=FALSE, fig.dim=c(6, 2), out.extra="", fig.cap="Optimised parameters across the range of potential fatigue limits"}
gammas <- seq(1, min(fatigue$s), by = 1)

conf_ints <- purrr::map_dfr(gammas, function(g) {
  
  opt <- optim(
    par = theta0,
    fn = N_nll_const_gamma,
    gr = N_nll_gr_const_gamma,
    y = fatigue$N,
    gamma = g,
    stress = fatigue$s,
    runout = fatigue$ro,
    method = "BFGS",
    hessian = TRUE
  )
  
  std_errs <- sqrt(diag(solve(opt$hessian)))
  
  data.frame(gamma = g, param = names(theta0), value = opt$par,
             lower = opt$par - qnorm(0.975)*std_errs,
             upper = opt$par + qnorm(0.975)*std_errs)
  
})


ggplot(conf_ints, aes(x = gamma, fill = param)) +
  geom_line(aes(y = value, color = param), lwd = 1) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
  facet_wrap(~ param, scales = "free_y") +
  theme_bw() + guides(color = FALSE, fill = FALSE)


```



### Section 2.2: Estimation of fatigue limit
  
Theoretically, rather than selecting $\gamma$ ourselves it is possible to include it in the optimisation. The only slight technicality is that we must transform $\gamma$ from its current bounded interval - specifically, $\gamma \in \left( 0, \min(s_i) \right)$ - onto an unbounded interval. This is achievable via the logit transformation, i.e. we optimise using
$$\text{l\_gamma} = \text{logit} \left( \frac{\gamma}{\min(s_i)} \right) = \log \left( \frac{\gamma}{\min(s_i) - \gamma} \right)$$

The code from Section 2.1 can be adapted easily by replacing `gamma` with `min_s/(1 + exp(-l_gamma))` and by adding `l_gamma` to the list of parameters for which we would like to return a gradient. Optimisation can then be performed as in Section 2.1.

  
```{r p2q2_N_funcs, echo=FALSE}
# Expressions for Weibull probability density function and Weibull survival function
# l_gamma is logit (inverse sigmoid) transform of gamma, i.e.
#  l_gamma = log(gamma / (min(fatigue$s) - gamma))
N_prob <- deriv(
  expression(
    -log_sigma - log_alpha - delta*log(s - min_s/(1 + exp(-l_gamma))) +
      ((1/exp(log_sigma)) - 1) * (log(y) - log_alpha - delta*log(s - min_s/(1 + exp(-l_gamma)))) -
      (y / (exp(log_alpha) * (s - min_s/(1 + exp(-l_gamma)))^delta))^(1/exp(log_sigma))
  ),
  namevec = c("log_alpha", "delta", "log_sigma", "l_gamma"),
  function.arg = c("y", "s", "min_s", "log_alpha", "delta", "log_sigma", "l_gamma"),
  hessian = TRUE
)


N_surv <- deriv(
  expression(
    -(y / (exp(log_alpha) * (s - min_s/(1 + exp(-l_gamma)))^delta))^(1/exp(log_sigma))
  ),
  namevec = c("log_alpha", "delta", "log_sigma", "l_gamma"),
  function.arg = c("y", "s", "min_s", "log_alpha", "delta", "log_sigma", "l_gamma"),
  hessian = TRUE
)



# Negative log-likelihood
N_nll <- function(theta, y, stress, runout) {
  
  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  l_gamma <- theta[4]
  
  -sum(
    (1-runout) * N_prob(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma),
    runout * N_surv(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma)
  )
}


# Gradient of negative log-likelihood
N_nll_gr <- function(theta, y, stress, runout) {
  
  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  l_gamma <- theta[4]
  
  -colSums(rbind(
    (1-runout) * attr(N_prob(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma), "gradient"),
    runout * attr(N_surv(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma), "gradient")
  ))
}
```

```{r p2q2_opt}
# Initial params
# Certain combinations seem to lead to strange (non-optimal) results...
# e.g. c(1, 1, 1, 1)
theta0 <- c("log_alpha" = 2, "delta" = 1, "log_sigma" = 2, "l_gamma" = 0)

# Minimise negative log-likelihood
N_opt <- optim(
  par = theta0,
  fn = N_nll,
  gr = N_nll_gr,
  y = fatigue$N,
  stress = fatigue$s,
  runout = fatigue$ro,
  method = "BFGS",
  hessian = TRUE
)
```

We can then calculate confidence intervals for these parameters in exactly the same way as before, using the negative Hessian returned by the optimisation.

```{r p2q2_std_err, echo=FALSE}
# Calculate standard errors from inverse Hessian
N_std_err <- sqrt(diag(solve(N_opt$hessian)))

# 95% confidence interval for each parameter
# Note asymptotic distribution is normal
round(data.frame(
  val = N_opt$par,
  se = N_std_err,
  lower = N_opt$par - qnorm(0.975)*N_std_err,
  upper = N_opt$par + qnorm(0.975)*N_std_err
), 3)
```

The optimised value of $\gamma$ can be retrieved using the inverse-logit (sigmoid) transformation:

```{r p2q2_gamma}
# Recover optimal gamma
min(fatigue$s) / (1 + exp(-N_opt$par[4]))
```

Interestingly, this "optimal" $\gamma$ seems to lie just before the upward turn seen in Figure \ref{fig:p2q1_param_plots}, providing further evidence that the relationship between $\sigma$ and $\gamma$ is the most important factor contributing to the distribution of $N_i$.



### Section 2.3: Important quantiles of approximated distribution
  
Using the optimised parameters from the previous section, we can compute approximate 10% and 50% quantiles for the distribution of $N$ over the range of stress values used in the fatigue testing. These are shown, alongside the recorded observations, in Figure \ref{fig:p2q3_stress_plot}; note that all but one of our observations lie clearly above the 10% quantile.

```{r p2q3_stress_plot, echo=FALSE, fig.height=3, out.extra = "", fig.cap="Quantiles of our approximated distribution of N"}
# Use parameters from previous optimisation
alpha <- exp(N_opt$par[1])
delta <- N_opt$par[2]
sigma <- exp(N_opt$par[3])
gamma <- min(fatigue$s) / (1 + exp(-N_opt$par[4]))


library(ggplot2)

ggplot(fatigue, aes(x = s)) +
  geom_point(aes(y = N)) +
  stat_function(fun = function(s) {alpha * (s - gamma)^delta * qweibull(0.1, shape = 1, scale = 1)}, aes(color = "10% quantile")) +
  stat_function(fun = function(s) {alpha * (s - gamma)^delta * qweibull(0.5, shape = 1, scale = 1)}, aes(color = "50% quantile"), linetype = "dashed") +
  labs(x = "Stress", y = "N", color = "Estimated quantiles") +
  theme_bw() + theme(legend.position = c(0.85, 0.8), legend.background = element_rect(color = "black"), legend.title = element_blank())
```



### Section 2.4: Modelling fatigue limit as a random effect
  
Similar to P1Q5
  
```{r q4_mcmc, eval=FALSE}

log_posterior <- function(theta, y, b, stress, runout) {
  
  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  mu_gamma <- theta[4]
  log_sigma_gamma <- theta[5]
  
  l_gamma <- log(b / (min(stress)-b))
  
  # Log conditional density of y given b
  lfy_b <- sum(
    (1-runout) * N_prob(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma),
    runout * N_surv(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma)
  )
  
  # Log marginal density of b
  lfb <- sum(dweibull(x = b, shape = 1/exp(log_sigma_gamma), scale = exp(mu_gamma), log = TRUE))
  
  # Log joint density of y and b is the sum (joint density is product - y, b are independent)
  lf <- lfy_b + lfb
  
  # Define log-prior (sum of log-priors for all parameters - here, just for log_sigma_b)
  log_prior <- dexp(exp(log_sigma_gamma), rate = 5, log = TRUE)
  
  # Log-posterior is log-prior plus log-likelihood
  lf + log_prior
  
}


log_posterior(c(1, 1, 1, 1, 1), fatigue$N, rep(0.1, 26), fatigue$s, fatigue$ro)




iters <- 100000
burnin <- 2000
pilot <- mcmc_mh(
  iters, burnin,
  c(log_alpha = 18, delta = -2, log_sigma = -1, mu_gamma = 4, log_sigma_gamma = -2),
  rep(66, 26), rep(0.03, 5), 0.12,
  fatigue$N, fatigue$s, fatigue$ro
)


D <- cbind(pilot$theta, pilot$b)[(burnin+1):iters, ]
cov_D <- cov(D)


adjusted <- mcmc_mh_cov(
  50000, 1000,
  drop(tail(pilot$theta, 1)),
  drop(tail(pilot$b, 1)), cov_D, 0.2,
  fatigue$N, fatigue$s, fatigue$ro
)



adjD <- cbind(adjusted$theta, adjusted$b)[-(1:burnin), ]
psych::pairs.panels(tail(adjD, 5000)[, 1:ncol(adjusted$theta)], pch = ".")


par(mfrow = c(2, 3))

ks_pvals <- vapply(colnames(adjusted$theta), function(nm) {
  
  # Calculate autocorrelation in MH sample for parameter
  y <- adjusted$theta[-(1:burnin), nm]
  autocorr <- acf(y, main = nm)
  
  # Autocorrelation length
  acl <- 2*sum(autocorr$acf) + 1
  
  # Sample of acl-spaced observations
  ac_smp <- y[seq(from = 1, to = length(y), by = acl)]
  
  # Test whether two halves of this sample are from same distribution
  # If p-value is significant, this means samples are (likely) from same dist
  idx <- sample(1:length(ac_smp), ceiling(length(ac_smp)/2), replace = FALSE)
  ks.test(ac_smp[idx], ac_smp[-idx])$p.value
  
}, FUN.VALUE = 0)

par(mfrow = c(1, 1))

# p-values as just calculated
ks_pvals



# Credible intervals for each parameter
cred_ints <- vapply(colnames(adjusted$theta), function(nm) {
  
  y <- adjusted$theta[-(1:burnin), nm]
  quantile(y, c(0.025, 0.975))
  
}, FUN.VALUE = c(0, 0))

cred_ints
```





```{r q4_intgrl, eval=FALSE}
intgrl <- function(theta) {

  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  mu_gamma <- theta[4]
  log_sigma_gamma <- theta[5]

  vapply(seq_len(nrow(fatigue)), function(k) {
    integrate(
      function(gamma) {
        ((1-fatigue$ro[k]) * dweibull(fatigue$N[k],
                                      shape = 1/exp(log_sigma),
                                      scale = (exp(log_alpha)*(fatigue$s[k] - gamma)^delta)) +
           fatigue$ro[k] * pweibull(fatigue$N[k],
                                    shape = 1/exp(log_sigma),
                                    scale = (exp(log_alpha)*(fatigue$s[k] - gamma)^delta),
                                    lower.tail = FALSE)) *
          dweibull(gamma, shape = 1/exp(log_sigma_gamma), scale = exp(mu_gamma))
      },
      lower = 0, upper = fatigue$s[k]
    )$value
  }, FUN.VALUE = 0)

}


# Calculate log posterior again but now without any priors
log_post_no_prior <- function(theta, y, b, stress, runout) {

  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  mu_gamma <- theta[4]
  log_sigma_gamma <- theta[5]

  l_gamma <- log(b / (min(stress)-b))

  # Log conditional density of y given b
  lfy_b <- sum(
    (1-runout) * N_prob(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma),
    runout * N_surv(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma)
  )

  # Log marginal density of b
  lfb <- sum(dweibull(x = b, shape = 1/exp(log_sigma_gamma), scale = exp(mu_gamma), log = TRUE))

  # Log joint density of y and b is the sum (joint density is product - y, b are independent)
  lfy_b + lfb
}


# Create full proposal distribution with denominator included
log_posterior <- function(theta, y, b, stress, runout) {
  l_fn <- sum(log(intgrl(theta)))
  l_fn_b_fb <- log_post_no_prior(theta, y, b, stress, runout)
  l_fn_b_fb - l_fn
}

# MCMC again (still taking correlation into account) with full posterior
adjusted_new <- mcmc_mh_cov(
  50000, 1000,
  drop(tail(pilot$theta, 1)),
  drop(tail(pilot$b, 1)), cov_D, 0.25,
  fatigue$N, fatigue$s, fatigue$ro
)
````
