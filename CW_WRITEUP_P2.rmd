---
title: 'MA40198: Applied Statistical Inference'
author: "20965, 20949 and 20969"
date: "23/11/2018"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)


mcmc_mh <- function(iters, burnin, init_params, init_bs, tuners, b_tuner, y, X, Z, show_plot = TRUE) {
  
  theta_vals <- matrix(NA, nrow = iters+1, ncol = length(init_params))
  colnames(theta_vals) <- names(init_params)
  theta_vals[1, ] <- init_params
  
  b_vals <- matrix(NA, nrow = iters+1, ncol = length(init_bs))
  b_vals[1, ] <- init_bs
  
  acceptance <- rep(NA, iters)
  acceptance_b <- rep(NA, iters)
  
  log_post <- log_posterior(init_params, y, init_bs, X, Z)
  
# Progress bar in console
  pb <- txtProgressBar(min = 0, max = iters, style = 3)
  
  
  # MCMC loop
  for (k in seq_len(iters)) {
    
    
    # "Non-random" parameters
    theta_prop <- rnorm(length(init_params), mean = theta_vals[k, ], sd = tuners)
    
    
    log_post_prop <- log_posterior(theta_prop, y, b_vals[k, ], X, Z)
    
    accept_prob <- exp(log_post_prop - log_post)
    
    if (accept_prob > runif(1)) {
      
      theta_vals[k+1, ] <- theta_prop
      log_post <- log_post_prop
      acceptance[k] <- TRUE
      
    } else {
      
      theta_vals[k+1, ] <- theta_vals[k, ]
      acceptance[k] <- FALSE
    }
    
    
    # "Random" parameters (proposed/accepted separately)
    
    # Now hold other parameters steady
    # Random effects have standard deviation exp(log_sigma_b)
    b_prop <- rnorm(length(init_bs), mean = b_vals[k, ], sd = b_tuner)
    
    # Use (possibly newly accepted) values of theta
    log_post_prop_b <- log_posterior(theta_vals[k+1, ], y, b_prop, X, Z)
    
    accept_prob_b <- exp(log_post_prop_b - log_post)
    
    if (accept_prob_b > runif(1)) {
      
      b_vals[k+1, ] <- b_prop
      log_post <- log_post_prop_b
      acceptance_b[k] <- TRUE
      
    } else {
      
      b_vals[k+1, ] <- b_vals[k, ]
      acceptance_b[k] <- FALSE
    }
    
    setTxtProgressBar(pb, value = k)
  }
  
  
  if (show_plot) {
    
    rows <- floor(sqrt(ncol(theta_vals)))
    par(mfrow = c(rows, rows+(ncol(theta_vals)%%2)))
    
    lapply(names(init_params), function(nm) {
      y <- theta_vals[, nm]
      plot(y, type = "l", main = nm, xlab = "Iteration", ylab = nm)
      rect(0, min(y), burnin, max(y), density = 10, col = "red")
    })
    
    par(mfrow = c(1, 1))
  }
  
  close(pb)
  cat(sprintf("Total acceptance:       %2.3f%%\n", mean(acceptance)*100))
  cat(sprintf("Burned-in acceptance:   %2.3f%%\n", mean(acceptance[-(1:burnin)])*100))
  cat(sprintf("Burned-in b acceptance: %2.3f%%\n", mean(acceptance_b[-(1:burnin)])*100))
  
  list(theta = theta_vals, b = b_vals)
}



mcmc_mh_cov <- function(iters, burnin, init_params, init_bs, cov_matrix, tuner, y, X, Z, show_plot = TRUE) {
  
  theta_vals <- matrix(NA, nrow = iters+1, ncol = length(init_params))
  colnames(theta_vals) <- names(init_params)
  theta_vals[1, ] <- init_params
  
  b_vals <- matrix(NA, nrow = iters+1, ncol = length(init_bs))
  b_vals[1, ] <- init_bs
  
  acceptance <- rep(NA, iters)
  
  log_post <- log_posterior(init_params, y, b_vals[1, ], X, Z)
  
  # Propositions for all iterations
  props <- MASS::mvrnorm(iters, mu = c(init_params, init_bs), Sigma = tuner^2 * cov_matrix)
  
  
  # Progress bar in console
  pb <- txtProgressBar(min = 0, max = iters, style = 3)
  
  
  # MCMC loop
  for (k in seq_len(iters)) {
    
    # Use proposed values for theta and b
    theta_prop <- props[k, 1:length(init_params)]
    b_prop <- props[k, (length(init_params)+1):ncol(props)]
    
    log_post_prop <- log_posterior(theta_prop, y, b_prop, X, Z)
    
    accept_prob <- exp(log_post_prop - log_post)
    
    if (accept_prob > runif(1)) {
      
      theta_vals[k+1, ] <- theta_prop
      b_vals[k+1, ] <- b_prop
      log_post <- log_post_prop
      acceptance[k] <- TRUE
      
    } else {
      
      theta_vals[k+1, ] <- theta_vals[k, ]
      b_vals[k+1, ] <- b_vals[k, ]
      acceptance[k] <- FALSE
    }
    
    
    setTxtProgressBar(pb, value = k)
  }
  
  
  if (show_plot) {
    
    rows <- floor(sqrt(ncol(theta_vals)))
    par(mfrow = c(rows, rows+(ncol(theta_vals)%%2)))
    
    lapply(names(init_params), function(nm) {
      y <- theta_vals[, nm]
      plot(y, type = "l", main = nm, xlab = "Iteration", ylab = nm)
      rect(0, min(y), burnin, max(y), density = 10, col = "red")
    })
    
    par(mfrow = c(1, 1))
  }
  
  close(pb)
  cat(sprintf("Total acceptance:       %2.3f%%\n", mean(acceptance)*100))
  cat(sprintf("Burned-in acceptance:   %2.3f%%\n", mean(acceptance[-(1:burnin)])*100))
  
  list(theta = theta_vals, b = b_vals)
}
```


```{r eval=FALSE}
install.packages("ggplot2")
install.packages("psych")
```  

```{r echo=FALSE}
set.seed(356476786) #use set.seed for reproducability, seed number found through random number generation
```


# Fatigue of Materials

```{r}
fatigue <- read.table("http://people.bath.ac.uk/kai21/ASI/fatigue.txt")
```



#### Question 1
  
  
  Need to use same code as Question 2 but without the gamma included



#### Question 2
  
Theoretically, rather than selecting $\gamma$ ourselves it is possible to include it in the optimisation. The only slight technicality is that we must transform $\gamma$ from its current bounded interval - specifically, $\gamma \in \left( 0, \min(s_i) \right)$ - onto an unbounded interval. This is achievable via the logit transformation, i.e. we optimise using
$$\text{l_gamma} = \text{logit} \left( \frac{\gamma}{\min(s_i)} \right) = \log \left( \frac{\gamma}{\min(s_i) - \gamma} \right)$$

The code from Question 1 can be adapted easily by replacing `gamma` with `min_s/(1 + exp(-l_gamma))` and by adding `l_gamma` to the list of parameters fow which we would like to return a gradient. Optimisation can then be performed as in Question 1.

  
```{r p2q2_N_funcs, echo=FALSE}
# Expressions for Weibull probability density function and Weibull survival function
# l_gamma is logit (inverse sigmoid) transform of gamma, i.e.
#  l_gamma = log(gamma / (min(fatigue$s) - gamma))
N_prob <- deriv(
  expression(
    -log_sigma - log_alpha - delta*log(s - min_s/(1 + exp(-l_gamma))) +
      ((1/exp(log_sigma)) - 1) * (log(y) - log_alpha - delta*log(s - min_s/(1 + exp(-l_gamma)))) -
      (y / (exp(log_alpha) * (s - min_s/(1 + exp(-l_gamma)))^delta))^(1/exp(log_sigma))
  ),
  namevec = c("log_alpha", "delta", "log_sigma", "l_gamma"),
  function.arg = c("y", "s", "min_s", "log_alpha", "delta", "log_sigma", "l_gamma"),
  hessian = TRUE
)


N_surv <- deriv(
  expression(
    -(y / (exp(log_alpha) * (s - min_s/(1 + exp(-l_gamma)))^delta))^(1/exp(log_sigma))
  ),
  namevec = c("log_alpha", "delta", "log_sigma", "l_gamma"),
  function.arg = c("y", "s", "min_s", "log_alpha", "delta", "log_sigma", "l_gamma"),
  hessian = TRUE
)



# Negative log-likelihood
N_nll <- function(theta, y, stress, runout) {
  
  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  l_gamma <- theta[4]
  
  -sum(
    (1-runout) * N_prob(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma),
    runout * N_surv(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma)
  )
}


# Gradient of negative log-likelihood
N_nll_gr <- function(theta, y, stress, runout) {
  
  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  l_gamma <- theta[4]
  
  -colSums(rbind(
    (1-runout) * attr(N_prob(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma), "gradient"),
    runout * attr(N_surv(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma), "gradient")
  ))
}
```

```{r p2q2_opt}
# Initial params
# Certain combinations seem to lead to strange (non-optimal) results...
# e.g. c(1, 1, 1, 1)
theta0 <- c("log_alpha" = 2, "delta" = 1, "log_sigma" = 2, "l_gamma" = 0)

# Minimise negative log-likelihood
N_opt <- optim(
  par = theta0,
  fn = N_nll,
  gr = N_nll_gr,
  y = fatigue$N,
  stress = fatigue$s,
  runout = fatigue$ro,
  method = "BFGS",
  hessian = TRUE
)
```

We can then calculate confidence intervals for these parameters in exactly the same way as before, using the negative Hessian returned by the optimisation.

```{r p2q2_std_err, echo=FALSE}
# Calculate standard errors from inverse Hessian
N_std_err <- sqrt(diag(solve(N_opt$hessian)))

# 95% confidence interval for each parameter
# Note asymptotic distribution is normal
round(data.frame(
  val = N_opt$par,
  se = N_std_err,
  lower = N_opt$par - qnorm(0.975)*N_std_err,
  upper = N_opt$par + qnorm(0.975)*N_std_err
), 3)
```

The optimised value of $\gamma$ can be retrieved using the inverse-logit (sigmoid) transformation:

```{r p2q2_gamma}
# Recover optimal gamma
min(fatigue$s) / (1 + exp(-N_opt$par[4]))
```



#### Question 3
  
  INSERT EXPLANATIONS HERE

```{r}

alpha <- exp(N_opt$par[1])
delta <- N_opt$par[2]
sigma <- exp(N_opt$par[3])
gamma <- min(fatigue$s) / (1 + exp(-N_opt$par[4]))


library(ggplot2)

ggplot(fatigue, aes(x = s)) +
  geom_point(aes(y = N)) +
  stat_function(fun = function(s) {alpha * (s - gamma)^delta * qweibull(0.1, shape = 1, scale = 1)}, aes(color = "10% quantile")) +
  stat_function(fun = function(s) {alpha * (s - gamma)^delta * qweibull(0.5, shape = 1, scale = 1)}, aes(color = "50% quantile"), linetype = "dashed") +
  ggtitle("Estimated quantiles of fatigue") + labs(x = "Stress", y = "N", color = "Estimated quantiles") +
  theme_bw() + theme(legend.position = c(0.8, 0.85), legend.background = element_rect(color = "black"))
```



#### Question 4
  
  As in question 5 of part 1:
  
```{r q4_mcmc, eval=FALSE}

log_posterior <- function(theta, y, b, stress, runout) {
  
  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  mu_gamma <- theta[4]
  log_sigma_gamma <- theta[5]
  
  l_gamma <- log(b / (min(stress)-b))
  
  # Log conditional density of y given b
  lfy_b <- sum(
    (1-runout) * N_prob(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma),
    runout * N_surv(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma)
  )
  
  # Log marginal density of b
  lfb <- sum(dweibull(x = b, shape = 1/exp(log_sigma_gamma), scale = exp(mu_gamma), log = TRUE))
  
  # Log joint density of y and b is the sum (joint density is product - y, b are independent)
  lf <- lfy_b + lfb
  
  # Define log-prior (sum of log-priors for all parameters - here, just for log_sigma_b)
  log_prior <- dexp(exp(log_sigma_gamma), rate = 5, log = TRUE)
  
  # Log-posterior is log-prior plus log-likelihood
  lf + log_prior
  
}


log_posterior(c(1, 1, 1, 1, 1), fatigue$N, rep(0.1, 26), fatigue$s, fatigue$ro)




iters <- 100000
burnin <- 2000
pilot <- mcmc_mh(
  iters, burnin,
  c(log_alpha = 18, delta = -2, log_sigma = -1, mu_gamma = 4, log_sigma_gamma = -2),
  rep(66, 26), rep(0.03, 5), 0.12,
  fatigue$N, fatigue$s, fatigue$ro
)


D <- cbind(pilot$theta, pilot$b)[(burnin+1):iters, ]
cov_D <- cov(D)


adjusted <- mcmc_mh_cov(
  50000, 1000,
  drop(tail(pilot$theta, 1)),
  drop(tail(pilot$b, 1)), cov_D, 0.2,
  fatigue$N, fatigue$s, fatigue$ro
)



adjD <- cbind(adjusted$theta, adjusted$b)[-(1:burnin), ]
psych::pairs.panels(tail(adjD, 5000)[, 1:ncol(adjusted$theta)], pch = ".")


par(mfrow = c(2, 3))

ks_pvals <- vapply(colnames(adjusted$theta), function(nm) {
  
  # Calculate autocorrelation in MH sample for parameter
  y <- adjusted$theta[-(1:burnin), nm]
  autocorr <- acf(y, main = nm)
  
  # Autocorrelation length
  acl <- 2*sum(autocorr$acf) + 1
  
  # Sample of acl-spaced observations
  ac_smp <- y[seq(from = 1, to = length(y), by = acl)]
  
  # Test whether two halves of this sample are from same distribution
  # If p-value is significant, this means samples are (likely) from same dist
  idx <- sample(1:length(ac_smp), ceiling(length(ac_smp)/2), replace = FALSE)
  ks.test(ac_smp[idx], ac_smp[-idx])$p.value
  
}, FUN.VALUE = 0)

par(mfrow = c(1, 1))

# p-values as just calculated
ks_pvals



# Credible intervals for each parameter
cred_ints <- vapply(colnames(adjusted$theta), function(nm) {
  
  y <- adjusted$theta[-(1:burnin), nm]
  quantile(y, c(0.025, 0.975))
  
}, FUN.VALUE = c(0, 0))

cred_ints
```





```{r q4_intgrl, eval=FALSE}
intgrl <- function(theta) {

  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  mu_gamma <- theta[4]
  log_sigma_gamma <- theta[5]

  vapply(seq_len(nrow(fatigue)), function(k) {
    integrate(
      function(gamma) {
        ((1-fatigue$ro[k]) * dweibull(fatigue$N[k],
                                      shape = 1/exp(log_sigma),
                                      scale = (exp(log_alpha)*(fatigue$s[k] - gamma)^delta)) +
           fatigue$ro[k] * pweibull(fatigue$N[k],
                                    shape = 1/exp(log_sigma),
                                    scale = (exp(log_alpha)*(fatigue$s[k] - gamma)^delta),
                                    lower.tail = FALSE)) *
          dweibull(gamma, shape = 1/exp(log_sigma_gamma), scale = exp(mu_gamma))
      },
      lower = 0, upper = fatigue$s[k]
    )$value
  }, FUN.VALUE = 0)

}


# Calculate log posterior again but now without any priors
log_post_no_prior <- function(theta, y, b, stress, runout) {

  log_alpha <- theta[1]
  delta <- theta[2]
  log_sigma <- theta[3]
  mu_gamma <- theta[4]
  log_sigma_gamma <- theta[5]

  l_gamma <- log(b / (min(stress)-b))

  # Log conditional density of y given b
  lfy_b <- sum(
    (1-runout) * N_prob(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma),
    runout * N_surv(y, stress, min(stress), log_alpha, delta, log_sigma, l_gamma)
  )

  # Log marginal density of b
  lfb <- sum(dweibull(x = b, shape = 1/exp(log_sigma_gamma), scale = exp(mu_gamma), log = TRUE))

  # Log joint density of y and b is the sum (joint density is product - y, b are independent)
  lfy_b + lfb
}


# Create full proposal distribution with denominator included
log_posterior <- function(theta, y, b, stress, runout) {
  l_fn <- sum(log(intgrl(theta)))
  l_fn_b_fb <- log_post_no_prior(theta, y, b, stress, runout)
  l_fn_b_fb - l_fn
}

# MCMC again (still taking correlation into account) with full posterior
adjusted_new <- mcmc_mh_cov(
  50000, 1000,
  drop(tail(pilot$theta, 1)),
  drop(tail(pilot$b, 1)), cov_D, 0.25,
  fatigue$N, fatigue$s, fatigue$ro
)
````
